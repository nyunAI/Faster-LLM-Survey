2024-01-18 09:03:12 INFO [__main__] max_memory: {0: '40GIB'}
2024-01-18 09:03:12 INFO [__main__] loading model and tokenizer
2024-01-18 09:03:12 WARNING [auto_gptq.modeling._base] You have activated both exllama and exllamav2 kernel. Setting disable_exllama to True and keeping disable_exllamav2 to False
2024-01-18 09:03:12 INFO [auto_gptq.modeling._base] lm_head not been quantized, will be ignored when make_quant.
2024-01-18 09:03:16 WARNING [auto_gptq.nn_modules.fused_llama_mlp] Skipping module injection for FusedLlamaMLPForQuantizedModel as currently not supported with use_triton=False.
2024-01-18 09:04:01 INFO [__main__] model and tokenizer loading time: 49.2140s
2024-01-18 09:04:01 INFO [__main__] model quantized: True
2024-01-18 09:04:01 INFO [__main__] quantize config: {'bits': 4, 'group_size': 128, 'damp_percent': 0.01, 'desc_act': False, 'static_groups': False, 'sym': True, 'true_sequential': True, 'model_name_or_path': 'exports/Llama-2-7b-hf/quant/gptq/q4_128g', 'model_file_base_name': 'gptq_model-4bit-128g'}
2024-01-18 09:04:01 INFO [__main__] model device map: OrderedDict([('', 0)])
2024-01-18 09:04:01 INFO [__main__] loading data
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 509.17 examples/s]
2024-01-18 09:04:02 INFO [__main__] generation config: {'max_length': 20, 'max_new_tokens': 128, 'min_length': 0, 'min_new_tokens': 128, 'early_stopping': False, 'max_time': None, 'do_sample': False, 'num_beams': 4, 'num_beam_groups': 1, 'penalty_alpha': None, 'use_cache': True, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'epsilon_cutoff': 0.0, 'eta_cutoff': 0.0, 'diversity_penalty': 0.0, 'repetition_penalty': 1.0, 'encoder_repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'bad_words_ids': None, 'force_words_ids': None, 'renormalize_logits': False, 'constraints': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'forced_decoder_ids': None, 'sequence_bias': None, 'guidance_scale': None, 'low_memory': None, 'num_return_sequences': 4, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'return_dict_in_generate': False, 'pad_token_id': 2, 'bos_token_id': None, 'eos_token_id': None, 'encoder_no_repeat_ngram_size': 0, 'decoder_start_token_id': None, 'num_assistant_tokens': 5, 'num_assistant_tokens_schedule': 'heuristic', 'generation_kwargs': {}, '_from_model_config': False, 'transformers_version': '4.36.2'}
2024-01-18 09:04:02 INFO [__main__] benchmark generation speed
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:05<?, ?it/s, num_tokens=512, speed=92.5323tokens/s, time=5.53] 10%|█         | 1/10 [00:05<00:49,  5.55s/it, num_tokens=512, speed=92.5323tokens/s, time=5.53] 10%|█         | 1/10 [00:09<00:49,  5.55s/it, num_tokens=512, speed=116.3654tokens/s, time=4.4] 20%|██        | 2/10 [00:09<00:39,  4.88s/it, num_tokens=512, speed=116.3654tokens/s, time=4.4] 20%|██        | 2/10 [00:14<00:39,  4.88s/it, num_tokens=512, speed=125.0998tokens/s, time=4.09] 30%|███       | 3/10 [00:14<00:31,  4.53s/it, num_tokens=512, speed=125.0998tokens/s, time=4.09] 30%|███       | 3/10 [00:18<00:31,  4.53s/it, num_tokens=512, speed=124.8965tokens/s, time=4.1]  40%|████      | 4/10 [00:18<00:26,  4.36s/it, num_tokens=512, speed=124.8965tokens/s, time=4.1] 40%|████      | 4/10 [00:22<00:26,  4.36s/it, num_tokens=512, speed=118.3275tokens/s, time=4.33] 50%|█████     | 5/10 [00:22<00:21,  4.36s/it, num_tokens=512, speed=118.3275tokens/s, time=4.33] 50%|█████     | 5/10 [00:26<00:21,  4.36s/it, num_tokens=512, speed=122.4033tokens/s, time=4.18] 60%|██████    | 6/10 [00:26<00:17,  4.30s/it, num_tokens=512, speed=122.4033tokens/s, time=4.18] 60%|██████    | 6/10 [00:31<00:17,  4.30s/it, num_tokens=512, speed=119.3609tokens/s, time=4.29] 70%|███████   | 7/10 [00:31<00:12,  4.30s/it, num_tokens=512, speed=119.3609tokens/s, time=4.29] 70%|███████   | 7/10 [00:35<00:12,  4.30s/it, num_tokens=512, speed=117.2702tokens/s, time=4.37] 80%|████████  | 8/10 [00:35<00:08,  4.33s/it, num_tokens=512, speed=117.2702tokens/s, time=4.37] 80%|████████  | 8/10 [00:39<00:08,  4.33s/it, num_tokens=512, speed=114.8869tokens/s, time=4.46] 90%|█████████ | 9/10 [00:39<00:04,  4.37s/it, num_tokens=512, speed=114.8869tokens/s, time=4.46] 90%|█████████ | 9/10 [00:43<00:04,  4.37s/it, num_tokens=512, speed=125.4319tokens/s, time=4.08]100%|██████████| 10/10 [00:43<00:00,  4.29s/it, num_tokens=512, speed=125.4319tokens/s, time=4.08]100%|██████████| 10/10 [00:43<00:00,  4.40s/it, num_tokens=512, speed=125.4319tokens/s, time=4.08]
2024-01-18 09:04:46 INFO [__main__] generated 5120 tokens using 43.82907772064209 seconds, generation speed: 116.8174250125424 tokens/s

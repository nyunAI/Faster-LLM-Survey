2024-01-18 09:00:39 INFO [__main__] max_memory: {0: '40GIB'}
2024-01-18 09:00:39 INFO [__main__] loading model and tokenizer
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.52s/it]
2024-01-18 09:00:45 INFO [__main__] model and tokenizer loading time: 5.6714s
2024-01-18 09:00:45 INFO [__main__] model quantized: False
2024-01-18 09:00:45 INFO [__main__] quantize config: {'bits': 4, 'group_size': -1, 'damp_percent': 0.01, 'desc_act': True, 'static_groups': False, 'sym': True, 'true_sequential': True, 'model_name_or_path': None, 'model_file_base_name': None}
2024-01-18 09:00:45 INFO [__main__] model device map: OrderedDict([('', 0)])
2024-01-18 09:00:45 INFO [__main__] loading data
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 616.24 examples/s]
2024-01-18 09:00:45 INFO [__main__] generation config: {'max_length': 20, 'max_new_tokens': 128, 'min_length': 0, 'min_new_tokens': 128, 'early_stopping': False, 'max_time': None, 'do_sample': False, 'num_beams': 4, 'num_beam_groups': 1, 'penalty_alpha': None, 'use_cache': True, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'epsilon_cutoff': 0.0, 'eta_cutoff': 0.0, 'diversity_penalty': 0.0, 'repetition_penalty': 1.0, 'encoder_repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'bad_words_ids': None, 'force_words_ids': None, 'renormalize_logits': False, 'constraints': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'forced_decoder_ids': None, 'sequence_bias': None, 'guidance_scale': None, 'low_memory': None, 'num_return_sequences': 4, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'return_dict_in_generate': False, 'pad_token_id': 2, 'bos_token_id': None, 'eos_token_id': None, 'encoder_no_repeat_ngram_size': 0, 'decoder_start_token_id': None, 'num_assistant_tokens': 5, 'num_assistant_tokens_schedule': 'heuristic', 'generation_kwargs': {}, '_from_model_config': False, 'transformers_version': '4.36.2'}
2024-01-18 09:00:45 INFO [__main__] benchmark generation speed
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:05<?, ?it/s, num_tokens=512, speed=90.7880tokens/s, time=5.64] 10%|█         | 1/10 [00:05<00:50,  5.65s/it, num_tokens=512, speed=90.7880tokens/s, time=5.64] 10%|█         | 1/10 [00:09<00:50,  5.65s/it, num_tokens=512, speed=118.5002tokens/s, time=4.32] 20%|██        | 2/10 [00:09<00:39,  4.88s/it, num_tokens=512, speed=118.5002tokens/s, time=4.32] 20%|██        | 2/10 [00:13<00:39,  4.88s/it, num_tokens=512, speed=129.0497tokens/s, time=3.97] 30%|███       | 3/10 [00:13<00:31,  4.47s/it, num_tokens=512, speed=129.0497tokens/s, time=3.97] 30%|███       | 3/10 [00:18<00:31,  4.47s/it, num_tokens=512, speed=127.1859tokens/s, time=4.03] 40%|████      | 4/10 [00:18<00:25,  4.30s/it, num_tokens=512, speed=127.1859tokens/s, time=4.03] 40%|████      | 4/10 [00:22<00:25,  4.30s/it, num_tokens=512, speed=123.7869tokens/s, time=4.14] 50%|█████     | 5/10 [00:22<00:21,  4.25s/it, num_tokens=512, speed=123.7869tokens/s, time=4.14] 50%|█████     | 5/10 [00:26<00:21,  4.25s/it, num_tokens=512, speed=126.1976tokens/s, time=4.06] 60%|██████    | 6/10 [00:26<00:16,  4.19s/it, num_tokens=512, speed=126.1976tokens/s, time=4.06] 60%|██████    | 6/10 [00:30<00:16,  4.19s/it, num_tokens=512, speed=123.4449tokens/s, time=4.15] 70%|███████   | 7/10 [00:30<00:12,  4.18s/it, num_tokens=512, speed=123.4449tokens/s, time=4.15] 70%|███████   | 7/10 [00:34<00:12,  4.18s/it, num_tokens=512, speed=123.3916tokens/s, time=4.15] 80%|████████  | 8/10 [00:34<00:08,  4.17s/it, num_tokens=512, speed=123.3916tokens/s, time=4.15] 80%|████████  | 8/10 [00:38<00:08,  4.17s/it, num_tokens=512, speed=119.3724tokens/s, time=4.29] 90%|█████████ | 9/10 [00:38<00:04,  4.21s/it, num_tokens=512, speed=119.3724tokens/s, time=4.29] 90%|█████████ | 9/10 [00:42<00:04,  4.21s/it, num_tokens=512, speed=129.6597tokens/s, time=3.95]100%|██████████| 10/10 [00:42<00:00,  4.14s/it, num_tokens=512, speed=129.6597tokens/s, time=3.95]100%|██████████| 10/10 [00:42<00:00,  4.28s/it, num_tokens=512, speed=129.6597tokens/s, time=3.95]
2024-01-18 09:01:28 INFO [__main__] generated 5120 tokens using 42.68140149116516 seconds, generation speed: 119.95857261294043tokens/s

You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.
BASE: /home/shwu/LLM-Efficiency-Survey
MODEL: /home/shwu/LLM-Efficiency-Survey/model
MODEL_PATH: /home/shwu/LLM-Efficiency-Survey/model/Llama-2-7b-hf
METHOD_EXPORTS: /home/shwu/LLM-Efficiency-Survey/exports/Llama-2-7b-hf/quant/hf


=================================== Quant: gptq_4_exllama_version_one ===================================
Output: What is the meaning of life? I've asked myself this question on many occasions. everybody wants to know the answer to this question. There are many theories and beliefs. Some say it is to enjoy life, some say it is to find a purpose, some say it is to live a good life. But what does the bible say?
The Bible is the most popular book in the world. It has been translated into over 1,500 languages and is read by more than 2.2 billion people. It is also the best-selling book of all time.
The Bible is a collection of 66 books written by
======================================== Stats ========================================
Generated 128 tokens in 4.205398321151733 seconds (30.43706926789865 tokens/s)
================================================================================



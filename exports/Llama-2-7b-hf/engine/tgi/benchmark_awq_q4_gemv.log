[2m2024-01-20T14:39:58.815085Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Args { model_id: "/home/shwu/LLM-Efficiency-Survey/exports/Llama-2-7b-hf/quant/awq/q4_gemv", revision: None, validation_workers: 2, sharded: None, num_shard: None, quantize: Some(Awq), speculate: None, dtype: None, trust_remote_code: false, max_concurrent_requests: 128, max_best_of: 2, max_stop_sequences: 4, max_top_n_tokens: 5, max_input_length: 1024, max_total_tokens: 2048, waiting_served_ratio: 1.2, max_batch_prefill_tokens: 4096, max_batch_total_tokens: None, max_waiting_tokens: 20, hostname: "0.0.0.0", port: 3000, shard_uds_path: "/tmp/text-generation-server", master_addr: "localhost", master_port: 29500, huggingface_hub_cache: None, weights_cache_override: None, disable_custom_kernels: false, cuda_memory_fraction: 1.0, rope_scaling: None, rope_factor: None, json_output: false, otlp_endpoint: None, cors_allow_origin: [], watermark_gamma: None, watermark_delta: None, ngrok: false, ngrok_authtoken: None, ngrok_edge: None, env: false }
[2m2024-01-20T14:39:58.815309Z[0m [32m INFO[0m [1mdownload[0m: [2mtext_generation_launcher[0m[2m:[0m Starting download process.
[2m2024-01-20T14:40:01.339529Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Files are already present on the host. Skipping download.

[2m2024-01-20T14:40:01.818888Z[0m [32m INFO[0m [1mdownload[0m: [2mtext_generation_launcher[0m[2m:[0m Successfully downloaded weights.
[2m2024-01-20T14:40:01.819155Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Starting shard [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:40:05.651528Z[0m [33m WARN[0m [2mtext_generation_launcher[0m[2m:[0m Could not import Flash Attention enabled models: No module named 'vllm'

[2m2024-01-20T14:40:11.829627Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Waiting for shard to be ready... [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:40:21.840661Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Waiting for shard to be ready... [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:40:31.853100Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Waiting for shard to be ready... [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:40:41.864320Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Waiting for shard to be ready... [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:40:51.876541Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Waiting for shard to be ready... [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:41:00.949437Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Server started at unix:///tmp/text-generation-server-0

[2m2024-01-20T14:41:00.987194Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Shard ready in 59.167250633s [2m[3mrank[0m[2m=[0m0[0m
[2m2024-01-20T14:41:01.075021Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Starting Webserver
[2m2024-01-20T14:41:01.147669Z[0m [33m WARN[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m246:[0m Could not find tokenizer config locally and no revision specified
[2m2024-01-20T14:41:01.147697Z[0m [33m WARN[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m258:[0m no pipeline tag found for model /home/shwu/LLM-Efficiency-Survey/exports/Llama-2-7b-hf/quant/awq/q4_gemv
[2m2024-01-20T14:41:01.155777Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m277:[0m Warming up model
[2m2024-01-20T14:41:03.172494Z[0m [33m WARN[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m291:[0m Model does not support automatic max batch total tokens
[2m2024-01-20T14:41:03.172515Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m313:[0m Setting max batch total tokens to 16000
[2m2024-01-20T14:41:03.172519Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m314:[0m Connected
[2m2024-01-20T14:41:11.779753Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.764086325s" [3mvalidation_time[0m[2m=[0m"307.534Âµs" [3mqueue_time[0m[2m=[0m"83.777Âµs" [3minference_time[0m[2m=[0m"3.763695268s" [3mtime_per_token[0m[2m=[0m"29.403869ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:15.521238Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.739201944s" [3mvalidation_time[0m[2m=[0m"224.245Âµs" [3mqueue_time[0m[2m=[0m"46.69Âµs" [3minference_time[0m[2m=[0m"3.738931195s" [3mtime_per_token[0m[2m=[0m"29.210399ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:19.261644Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.738149246s" [3mvalidation_time[0m[2m=[0m"186.85Âµs" [3mqueue_time[0m[2m=[0m"43.481Âµs" [3minference_time[0m[2m=[0m"3.737919223s" [3mtime_per_token[0m[2m=[0m"29.202493ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:23.002268Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.738361705s" [3mvalidation_time[0m[2m=[0m"193.532Âµs" [3mqueue_time[0m[2m=[0m"45.26Âµs" [3minference_time[0m[2m=[0m"3.738123092s" [3mtime_per_token[0m[2m=[0m"29.204086ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:26.751383Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.746772018s" [3mvalidation_time[0m[2m=[0m"190.11Âµs" [3mqueue_time[0m[2m=[0m"44.275Âµs" [3minference_time[0m[2m=[0m"3.746537829s" [3mtime_per_token[0m[2m=[0m"29.269826ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:30.506631Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.752881264s" [3mvalidation_time[0m[2m=[0m"187.245Âµs" [3mqueue_time[0m[2m=[0m"30.072Âµs" [3minference_time[0m[2m=[0m"3.7526643s" [3mtime_per_token[0m[2m=[0m"29.317689ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:34.301836Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.79284791s" [3mvalidation_time[0m[2m=[0m"185.889Âµs" [3mqueue_time[0m[2m=[0m"51.848Âµs" [3minference_time[0m[2m=[0m"3.792610467s" [3mtime_per_token[0m[2m=[0m"29.629769ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:38.050816Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.74660306s" [3mvalidation_time[0m[2m=[0m"220.32Âµs" [3mqueue_time[0m[2m=[0m"50.929Âµs" [3minference_time[0m[2m=[0m"3.746332322s" [3mtime_per_token[0m[2m=[0m"29.268221ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:41.803825Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.750720517s" [3mvalidation_time[0m[2m=[0m"185.58Âµs" [3mqueue_time[0m[2m=[0m"43.796Âµs" [3minference_time[0m[2m=[0m"3.750491321s" [3mtime_per_token[0m[2m=[0m"29.300713ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:45.548553Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(128), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.742450907s" [3mvalidation_time[0m[2m=[0m"186.217Âµs" [3mqueue_time[0m[2m=[0m"44.559Âµs" [3minference_time[0m[2m=[0m"3.742220309s" [3mtime_per_token[0m[2m=[0m"29.236096ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m296:[0m Success
[2m2024-01-20T14:41:45.553575Z[0m [32m INFO[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m974:[0m signal received, starting graceful shutdown
[2m2024-01-20T14:41:45.618779Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Terminating webserver
[2m2024-01-20T14:41:45.618921Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Waiting for webserver to gracefully shutdown
[2m2024-01-20T14:41:45.618951Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m webserver terminated
[2m2024-01-20T14:41:45.618956Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Shutting down shards
[2m2024-01-20T14:41:45.702943Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Shard terminated [2m[3mrank[0m[2m=[0m0[0m

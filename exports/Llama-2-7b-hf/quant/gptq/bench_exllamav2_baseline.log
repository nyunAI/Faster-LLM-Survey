2024-01-18 08:59:45 INFO [__main__] max_memory: {0: '40GIB'}
2024-01-18 08:59:45 INFO [__main__] loading model and tokenizer
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.50s/it]
2024-01-18 08:59:51 INFO [__main__] model and tokenizer loading time: 5.6569s
2024-01-18 08:59:51 INFO [__main__] model quantized: False
2024-01-18 08:59:51 INFO [__main__] quantize config: {'bits': 4, 'group_size': -1, 'damp_percent': 0.01, 'desc_act': True, 'static_groups': False, 'sym': True, 'true_sequential': True, 'model_name_or_path': None, 'model_file_base_name': None}
2024-01-18 08:59:51 INFO [__main__] model device map: OrderedDict([('', 0)])
2024-01-18 08:59:51 INFO [__main__] loading data
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 636.73 examples/s]
2024-01-18 08:59:51 INFO [__main__] generation config: {'max_length': 20, 'max_new_tokens': 128, 'min_length': 0, 'min_new_tokens': 128, 'early_stopping': False, 'max_time': None, 'do_sample': False, 'num_beams': 4, 'num_beam_groups': 1, 'penalty_alpha': None, 'use_cache': True, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'epsilon_cutoff': 0.0, 'eta_cutoff': 0.0, 'diversity_penalty': 0.0, 'repetition_penalty': 1.0, 'encoder_repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'bad_words_ids': None, 'force_words_ids': None, 'renormalize_logits': False, 'constraints': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'forced_decoder_ids': None, 'sequence_bias': None, 'guidance_scale': None, 'low_memory': None, 'num_return_sequences': 4, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'return_dict_in_generate': False, 'pad_token_id': 2, 'bos_token_id': None, 'eos_token_id': None, 'encoder_no_repeat_ngram_size': 0, 'decoder_start_token_id': None, 'num_assistant_tokens': 5, 'num_assistant_tokens_schedule': 'heuristic', 'generation_kwargs': {}, '_from_model_config': False, 'transformers_version': '4.36.2'}
2024-01-18 08:59:51 INFO [__main__] benchmark generation speed
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:05<?, ?it/s, num_tokens=512, speed=89.8925tokens/s, time=5.7] 10%|█         | 1/10 [00:05<00:51,  5.71s/it, num_tokens=512, speed=89.8925tokens/s, time=5.7] 10%|█         | 1/10 [00:10<00:51,  5.71s/it, num_tokens=512, speed=118.9937tokens/s, time=4.3] 20%|██        | 2/10 [00:10<00:39,  4.89s/it, num_tokens=512, speed=118.9937tokens/s, time=4.3] 20%|██        | 2/10 [00:14<00:39,  4.89s/it, num_tokens=512, speed=127.1811tokens/s, time=4.03] 30%|███       | 3/10 [00:14<00:31,  4.50s/it, num_tokens=512, speed=127.1811tokens/s, time=4.03] 30%|███       | 3/10 [00:18<00:31,  4.50s/it, num_tokens=512, speed=128.8116tokens/s, time=3.97] 40%|████      | 4/10 [00:18<00:25,  4.30s/it, num_tokens=512, speed=128.8116tokens/s, time=3.97] 40%|████      | 4/10 [00:22<00:25,  4.30s/it, num_tokens=512, speed=123.7756tokens/s, time=4.14] 50%|█████     | 5/10 [00:22<00:21,  4.25s/it, num_tokens=512, speed=123.7756tokens/s, time=4.14] 50%|█████     | 5/10 [00:26<00:21,  4.25s/it, num_tokens=512, speed=127.9025tokens/s, time=4]    60%|██████    | 6/10 [00:26<00:16,  4.17s/it, num_tokens=512, speed=127.9025tokens/s, time=4] 60%|██████    | 6/10 [00:30<00:16,  4.17s/it, num_tokens=512, speed=123.6373tokens/s, time=4.14] 70%|███████   | 7/10 [00:30<00:12,  4.16s/it, num_tokens=512, speed=123.6373tokens/s, time=4.14] 70%|███████   | 7/10 [00:34<00:12,  4.16s/it, num_tokens=512, speed=121.9613tokens/s, time=4.2]  80%|████████  | 8/10 [00:34<00:08,  4.18s/it, num_tokens=512, speed=121.9613tokens/s, time=4.2] 80%|████████  | 8/10 [00:38<00:08,  4.18s/it, num_tokens=512, speed=118.3267tokens/s, time=4.33] 90%|█████████ | 9/10 [00:38<00:04,  4.23s/it, num_tokens=512, speed=118.3267tokens/s, time=4.33] 90%|█████████ | 9/10 [00:42<00:04,  4.23s/it, num_tokens=512, speed=129.4968tokens/s, time=3.95]100%|██████████| 10/10 [00:42<00:00,  4.15s/it, num_tokens=512, speed=129.4968tokens/s, time=3.95]100%|██████████| 10/10 [00:42<00:00,  4.29s/it, num_tokens=512, speed=129.4968tokens/s, time=3.95]
2024-01-18 09:00:34 INFO [__main__] generated 5120 tokens using 42.75852179527283 seconds, generation speed: 119.74221242994518tokens/s

You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['fuse_max_seq_len', 'modules_to_fuse', 'do_fuse']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.
BASE: /home/shwu/LLM-Efficiency-Survey
MODEL: /home/shwu/LLM-Efficiency-Survey/model
MODEL_PATH: /home/shwu/LLM-Efficiency-Survey/model/Llama-2-7b-hf
METHOD_EXPORTS: /home/shwu/LLM-Efficiency-Survey/exports/Llama-2-7b-hf/quant/hf


=================================== Quant: awq_4_gemm ===================================
Output: What is the meaning of life? What is the meaning of death? What is the meaning of suffering? Why do we exist? Why do we suffer? Why do we die? Why is there evil in the world? Why is there pain and suffering in the world? Why is there suffering in the world? Why do we suffer? Why is there evil in the world? Why do we suffer? Why is there suffering in the world? Why is there evil in the world? Why is there suffering in the world? Why is there evil in the world? Why is there suffering in the world? Why is there evil in the world? Why do we suffer? Why do
======================================== Stats ========================================
Generated 128 tokens in 4.49007248878479 seconds (28.507334863683326 tokens/s)
================================================================================



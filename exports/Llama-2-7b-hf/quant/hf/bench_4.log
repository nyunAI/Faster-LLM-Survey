You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['fuse_max_seq_len', 'modules_to_fuse', 'do_fuse']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.
BASE: /home/shwu/LLM-Efficiency-Survey
MODEL: /home/shwu/LLM-Efficiency-Survey/model
MODEL_PATH: /home/shwu/LLM-Efficiency-Survey/model/Llama-2-7b-hf
METHOD_EXPORTS: /home/shwu/LLM-Efficiency-Survey/exports/Llama-2-7b-hf/quant/hf


=================================== Quant: awq_4_gemv ===================================
Output: What is the meaning of life? What is the meaning of death?
The meaning of life is to be happy. The meaning of death is to be unhappy no more.
What is the meaning of life? What is the meaning of death? The meaning of life is to be happy. The meaning of death is to be unhappy no more.
The meaning of life is to be happy. The meaning of death is to be unhappy no more.
The meaning of life is to be happy. The meaning of death is to be unhappy no more.
The meaning of life is to be happy. The meaning of death is to be unhappy
======================================== Stats ========================================
Generated 128 tokens in 4.024226188659668 seconds (31.807357240680457 tokens/s)
================================================================================


